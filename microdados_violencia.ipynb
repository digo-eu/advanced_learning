{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Use isto se for a primeira vez usando o datalake da basedosdados.org: <br>\n",
    "   pip install basedosdados\n",
    "<br><br>\n",
    "#Use para baixar a base como microdados_violencia.csv: <br>\n",
    "   import basedosdados as bd <br>\n",
    "   df = bd.read_table(dataset_id='br_ms_sinan', table_id='microdados_violencia', billing_project_id=\"violenciasinan\", use_bqstorage_api = True) <br>\n",
    "   df.to_csv(path_or_buf = 'microdados_violencia.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importar bibliotecas usadas\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.layers.experimental import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tf.__version__)\n",
    "try:\n",
    "    physical_devices = tf.config.list_physical_devices('GPU') \n",
    "    #tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "    for device in physical_devices:\n",
    "        tf.config.experimental.set_memory_growth(device, True)\n",
    "    print(physical_devices)\n",
    "except:\n",
    "    print(\"No GPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# carregar dados em um dataframe pandas\n",
    "# para usar o arquivo .csv baixe da pasta do sharepoint ou com os comandos disponíveis no topo do notebook e insira o caminho do arquivo no comando abaixo\n",
    "df = pd.read_csv(\"C:/Users/rozan/OneDrive - Fundacao Getulio Vargas - FGV/Eletivas/AdvLearning/microdados_violencia.csv\")\n",
    "# excluir colunas inadequadas para a análise\n",
    "df = df.drop(['houve_qual_outra_violencia_sexual', 'meio_qual_outro', 'ocorreu_qual_outra', 'outro_local_ocorrencia', 'quais_outras_deficiencias_paciente', 'autor_relacao_outros',\n",
    "'data_encerramento', 'data_notificacao', 'id_categoria_cid10', 'id_municipio_notificacao', 'id_municipio_6_notificacao', 'id_unidade_notificacao', 'id_regional_saude_notificacao',\n",
    "'id_municipio_ocorrencia', 'id_municipio_6_ocorrencia', 'id_municipio_residencia', 'id_municipio_6_residencia', 'id_regional_saude_residencia'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resumo dos dados\n",
    "with pd.option_context('display.max_rows', 5, 'display.max_columns', None): \n",
    "    display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separando labels e features\n",
    "features = df.copy()\n",
    "labels = features.pop('outras_vezes_ocorrencia')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = {}\n",
    "\n",
    "for name, column in features.items():\n",
    "  dtype = column.dtype\n",
    "  if dtype == object:\n",
    "    dtype = tf.string\n",
    "  else:\n",
    "    dtype = tf.float32\n",
    "\n",
    "  inputs[name] = tf.keras.Input(shape=(1,), name=name, dtype=dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# concatenar e normalizar dados numéricos\n",
    "numeric_inputs = {name:input for name,input in inputs.items()\n",
    "                  if input.dtype==tf.float32}\n",
    "\n",
    "x = layers.Concatenate()(list(numeric_inputs.values()))\n",
    "norm = preprocessing.Normalization()\n",
    "norm.adapt(np.array(df[numeric_inputs.keys()]))\n",
    "all_numeric_inputs = norm(x)\n",
    "preprocessed_inputs = [all_numeric_inputs]\n",
    "\n",
    "all_numeric_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modelo de regressão\n",
    "# SGD como otimizador\n",
    "modelo = tf.keras.Sequential([\n",
    "  layers.Dense(64),\n",
    "  layers.Dense(1)\n",
    "])\n",
    "\n",
    "modelo.compile(loss = tf.losses.MeanSquaredError(),\n",
    "                      optimizer = tf.optimizers.SGD())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo.fit(features, labels, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6fc91d41b786585812c82e68ecc82c1d85295c5bfe5f395a721e141c29967732"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
